# Multi-Layer Feature Circuits in Transformers

This repository hosts exploratory notebooks for studying feature circuits that emerge inside multi-layer transformer models. The initial Method_1.ipynb notebook reproduces the workflow used to inspect attention heads, visualize activations, and document findings from preliminary experiments.

## Getting Started

1. Ensure you have Python 3.10+ with JupyterLab or Jupyter Notebook installed.
2. Clone this repository and install the Python dependencies required by your environment (for example via pip install -r requirements.txt if you choose to capture them later).
3. Launch Jupyter and open Method_1.ipynb to step through the analysis.

## Next Steps

- Capture dependencies in a equirements.txt once the experimentation stack stabilizes.
- Add additional notebooks for new methods or ablation studies.
- Commit plots or intermediate data products that are helpful for reproducibility.
